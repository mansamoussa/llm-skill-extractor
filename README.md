# ğŸ§  Multi-Stage Job Advertisement Analysis using BERT and LLMs

**Team:**  
- MikaÃ«l Bonvin  
- Mouhamadou Thiam

**Institution:** HSLU â€“ Applied Information and Data Science Masterâ€™s Program  

---

## Project Overview

This project develops a **two-stage NLP pipeline**:
1. **Zone Identification:** Fine-tune a multilingual BERT model to classify text sections in job advertisements.
2. **Skill Extraction:** Use Google Gemini to extract professional skills from the â€œSkills and Contentâ€ zone.

Optional extension: a **multi-agent orchestration system** coordinating multiple LLMs for improved skill extraction robustness.

---

## Repository Structure

â”œâ”€â”€ data
â”‚Â Â  â””â”€â”€ annotated.json
â”œâ”€â”€ notebooks
â”‚Â Â  â”œâ”€â”€ 01_data_preparation.ipynb
â”‚Â Â  â”œâ”€â”€ 02_train_bert.ipynb
â”‚Â Â  â”œâ”€â”€ 03_evaluation.ipynb
â”‚Â Â  â”œâ”€â”€ 04_skill_extraction_llm.ipynb
â”‚Â Â  â””â”€â”€ 05_agent_orchestration_optional.ipynb
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ src
    â”œâ”€â”€ preprocessing.py
    â””â”€â”€ training_template.py

Each notebook is runnable in **Google Colab** â€” simply click the badge below:

[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mansamoussa/llm-skill-extractor/)

---

## Requirements

Install dependencies locally or in Colab:

```bash
pip install -r requirements.txt
