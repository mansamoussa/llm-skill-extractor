{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e3f575b4",
      "metadata": {
        "id": "e3f575b4"
      },
      "source": [
        "# Multi-Stage Job Advertisement Analysis — Training Bert Zone Identification Model\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mansamoussa/llm-skill-extractor/blob/main/notebooks/02_train_bert.ipynb)\n",
        "\n",
        "---\n",
        "\n",
        "### Objective\n",
        "Train a **multilingual BERT token classification model** that predicts zone labels for each token in a job advertisement, using the preprocessed datasets generated in *01_data_preparation.ipynb*.\n",
        "\n",
        "This notebook will:\n",
        "1. Load:\n",
        "   - The preprocessed `train_dataset` and `test_dataset`\n",
        "   - The `id2label.json` and `label2id.json` mappings  \n",
        "2. Initialize a `bert-base-multilingual-cased` model for token classification  \n",
        "3. Configure and run the full training loop:\n",
        "   - Optimizer (AdamW)\n",
        "   - Learning rate scheduler  \n",
        "   - Weighted loss function to handle class imbalance  \n",
        "   - Periodic validation  \n",
        "4. Save artifacts:\n",
        "   - The best-performing model checkpoint (`best_model.pt`)\n",
        "   - TensorBoard logs for visualization  \n",
        "5. Evaluate model performance using **seqeval** metrics:\n",
        "   - Precision  \n",
        "   - Recall  \n",
        "   - F1-score  \n",
        "\n",
        "### Input Data\n",
        "- `data/train_dataset.pt` — tokenized, labeled training chunks  \n",
        "- `data/test_dataset.pt` — tokenized, labeled evaluation chunks  \n",
        "- `model/id2label.json` — mapping from label IDs → label names  \n",
        "- `model/label2id.json` — mapping from label names → label IDs  \n",
        "\n",
        "### Output\n",
        "- **`model/best_model.pt`** — best model checkpoint based on validation loss  \n",
        "- **TensorBoard logs** stored under `logs/train/`  \n",
        "- **Evaluation results** including seqeval classification report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers seqeval tensorboard"
      ],
      "metadata": {
        "id": "ZRN9QOZyJ6xR",
        "outputId": "6b07f07a-d8d1-4cb6-a407-e8465a4eaa65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ZRN9QOZyJ6xR",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from transformers import (\n",
        "    BertForTokenClassification,\n",
        "    BertTokenizerFast,\n",
        "    get_linear_schedule_with_warmup\n",
        ")\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from seqeval.metrics import classification_report, f1_score\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "metadata": {
        "id": "8KsKQ-lRNNdw"
      },
      "id": "8KsKQ-lRNNdw",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d2ff4c2a",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "d2ff4c2a",
        "outputId": "269b2ae0-cce9-410c-97df-954b6afe55e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "PROJECT_ROOT = \"/content/drive/MyDrive/GroupWork_GEN03\"\n",
        "\n",
        "# Define paths\n",
        "train_dataset_path = f\"{PROJECT_ROOT}/processed_data/train_dataset.pt\"\n",
        "test_dataset_path  = f\"{PROJECT_ROOT}/processed_data/test_dataset.pt\"\n",
        "id2label_path      = f\"{PROJECT_ROOT}/model/id2label.json\"\n",
        "label2id_path      = f\"{PROJECT_ROOT}/model/label2id.json\"\n",
        "model_save_path    = f\"{PROJECT_ROOT}/model/best_model.pt\"\n",
        "\n",
        "paths = {\n",
        "    \"train_dataset.pt\": train_dataset_path,\n",
        "    \"test_dataset.pt\": test_dataset_path,\n",
        "    \"id2label.json\": id2label_path,\n",
        "    \"label2id.json\": label2id_path,\n",
        "}\n",
        "\n",
        "# Validate all paths\n",
        "missing = [name for name, p in paths.items() if not os.path.exists(p)]\n",
        "\n",
        "if missing:\n",
        "    raise FileNotFoundError(\n",
        "        \"❌ Missing required input files:\\n\" +\n",
        "        \"\\n\".join(f\" - {name}\" for name in missing) +\n",
        "        \"\\n\\nPlease verify where Notebook 01 has exported.\"\n",
        "    )\n",
        "else:\n",
        "    print(\"✅ All required files found.\")"
      ],
      "metadata": {
        "id": "tJNMRiJcKy46",
        "outputId": "26aaf3a0-06d3-4549-d60a-96ca37f84f73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "tJNMRiJcKy46",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All required files found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- For PyTorch 2.6 unpickling TensorDataset ---\n",
        "from torch.utils.data import TensorDataset\n",
        "import torch\n",
        "torch.serialization.add_safe_globals([TensorDataset])\n",
        "# -----------------------------------------------------\n",
        "\n",
        "# Load datasets (weights_only=False for full objects)\n",
        "train_dataset = torch.load(train_dataset_path, weights_only=False)\n",
        "test_dataset  = torch.load(test_dataset_path,  weights_only=False)\n",
        "\n",
        "# Load id2label mapping (keys are strings, convert to int)\n",
        "with open(id2label_path, \"r\") as f:\n",
        "    id2label_raw = json.load(f)\n",
        "\n",
        "# Convert: {\"0\": \"O\"} to {0: \"O\"}\n",
        "id2label = {int(k): v for k, v in id2label_raw.items()}\n",
        "\n",
        "# Create label2id: {\"O\": 0, ...}\n",
        "label2id = {v: k for k, v in id2label.items()}\n",
        "\n",
        "num_labels = len(label2id)\n",
        "\n",
        "id2label, label2id, num_labels"
      ],
      "metadata": {
        "id": "UrX0WQ7YNLZv",
        "outputId": "4cf5d5d0-191f-434e-8fcc-0db7def01adf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "UrX0WQ7YNLZv",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({0: 'O',\n",
              "  1: 'Fähigkeiten und Inhalte',\n",
              "  2: 'Abschlüsse',\n",
              "  3: 'Anstellung',\n",
              "  4: 'Erfahrung',\n",
              "  5: 'Challenges',\n",
              "  6: 'Bewerbungsprozess',\n",
              "  7: 'Firmenbeschreibung',\n",
              "  8: 'Benefits',\n",
              "  9: 'Arbeitsumfeld',\n",
              "  10: 'Firmenkundenbeschreibung'},\n",
              " {'O': 0,\n",
              "  'Fähigkeiten und Inhalte': 1,\n",
              "  'Abschlüsse': 2,\n",
              "  'Anstellung': 3,\n",
              "  'Erfahrung': 4,\n",
              "  'Challenges': 5,\n",
              "  'Bewerbungsprozess': 6,\n",
              "  'Firmenbeschreibung': 7,\n",
              "  'Benefits': 8,\n",
              "  'Arbeitsumfeld': 9,\n",
              "  'Firmenkundenbeschreibung': 10},\n",
              " 11)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "model = BertForTokenClassification.from_pretrained(\n",
        "    \"bert-base-multilingual-cased\",\n",
        "    num_labels=num_labels,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "device"
      ],
      "metadata": {
        "id": "J5eMDt4GXMF0"
      },
      "id": "J5eMDt4GXMF0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "len(train_loader), len(test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alig6TZdXOir",
        "outputId": "7e90c351-6351-4178-95c1-d4172b3ab1e8"
      },
      "id": "alig6TZdXOir",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(374, 94)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check: take one batch and run it through the model\n",
        "batch = next(iter(train_loader))\n",
        "input_ids, labels, attention_mask = [b.to(device) for b in batch]\n",
        "\n",
        "print(\"input_ids:\", input_ids.shape)\n",
        "print(\"attention_mask:\", attention_mask.shape)\n",
        "print(\"labels:\", labels.shape)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        labels=labels\n",
        "    )\n",
        "\n",
        "print(\"Forward pass OK — loss:\", outputs.loss.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4HaOVEec3mf",
        "outputId": "a941af8e-184b-4baa-96b9-e3cfe8ee2609"
      },
      "id": "s4HaOVEec3mf",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids: torch.Size([8, 510])\n",
            "attention_mask: torch.Size([8, 510])\n",
            "labels: torch.Size([8, 510])\n",
            "Forward pass OK — loss: 2.388327121734619\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_labels = []\n",
        "for _, labels, _ in train_loader:\n",
        "    all_labels.extend(labels.view(-1).numpy())\n",
        "\n",
        "all_labels = np.array(all_labels)\n",
        "valid_mask = all_labels != label2id[\"O\"]\n",
        "filtered_labels = all_labels[valid_mask]\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    classes=np.array(list(label2id.values())),\n",
        "    y=all_labels\n",
        ")\n",
        "\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "class_weights"
      ],
      "metadata": {
        "id": "KjsVbnRnXOf9"
      },
      "id": "KjsVbnRnXOf9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "learning_rate = 3e-5\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "num_training_steps = len(train_loader) * epochs\n",
        "num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    num_training_steps=num_training_steps,\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss(weight=class_weights, ignore_index=label2id[\"O\"])\n",
        "\n",
        "writer = SummaryWriter(log_dir=\"../logs/train\")"
      ],
      "metadata": {
        "id": "m7PqXnigXOcu"
      },
      "id": "m7PqXnigXOcu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss = float(\"inf\")\n",
        "save_path = \"../model/best_model.pt\"\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for step, batch in enumerate(train_loader):\n",
        "        input_ids, labels, attention_mask = [b.to(device) for b in batch]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "    writer.add_scalar(\"Loss/train\", avg_train_loss, epoch)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "    # ---------- VALIDATION ----------\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids, labels, attention_mask = [b.to(device) for b in batch]\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels\n",
        "            )\n",
        "            val_loss += outputs.loss.item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(test_loader)\n",
        "    writer.add_scalar(\"Loss/val\", avg_val_loss, epoch)\n",
        "\n",
        "    print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(\"✓ Saved new best model\")\n",
        "\n",
        "writer.close()"
      ],
      "metadata": {
        "id": "i7fLjcL2Xd1D"
      },
      "id": "i7fLjcL2Xd1D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"../model/best_model.pt\"))\n",
        "model.eval()\n",
        "print(\"Loaded best_model.pt\")"
      ],
      "metadata": {
        "id": "LwEfP3wrXdx2"
      },
      "id": "LwEfP3wrXdx2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_labels = []\n",
        "pred_labels = []\n",
        "\n",
        "for batch in test_loader:\n",
        "    input_ids, labels, attention_mask = [b.to(device) for b in batch]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "    for i in range(labels.size(0)):\n",
        "        true_seq = []\n",
        "        pred_seq = []\n",
        "        for t, p in zip(labels[i], preds[i]):\n",
        "            t = t.item()\n",
        "            p = p.item()\n",
        "\n",
        "            if t == label2id[\"O\"] and p == label2id[\"O\"]:\n",
        "                continue\n",
        "\n",
        "            true_seq.append(id2label[str(t)])\n",
        "            pred_seq.append(id2label[str(p)])\n",
        "\n",
        "        if true_seq:\n",
        "            true_labels.append(true_seq)\n",
        "            pred_labels.append(pred_seq)"
      ],
      "metadata": {
        "id": "efGhtukdXdta"
      },
      "id": "efGhtukdXdta",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"F1 Score:\", f1_score(true_labels, pred_labels))\n",
        "print()\n",
        "print(classification_report(true_labels, pred_labels))"
      ],
      "metadata": {
        "id": "ypDu1bsRXOZE"
      },
      "id": "ypDu1bsRXOZE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bIeOIHPCXOP2"
      },
      "id": "bIeOIHPCXOP2",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}